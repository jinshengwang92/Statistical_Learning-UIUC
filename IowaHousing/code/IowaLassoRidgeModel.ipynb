{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<DIV ALIGN=CENTER>\n",
    "# IOWA housing prediction with Lasso and Ridge Models\n",
    "</DIV>  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First to prepare the library necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: dummies\n",
      "dummies-1.5.6 provided by Decision Patterns\n",
      "\n",
      "Loading required package: DAAG\n",
      "Loading required package: lattice\n",
      "Loading required package: glmnet\n",
      "Loading required package: Matrix\n",
      "Loading required package: foreach\n",
      "Loaded glmnet 2.0-5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import required library\n",
    "if (!require(dummies)) {\n",
    "    install.packages(\"dummies\")   # for dummy variables\n",
    "}\n",
    "if (!require(DAAG)) {\n",
    "    install.packages(\"moments\")   # for data skwness judge\n",
    "}\n",
    "if (!require(DAAG)) {\n",
    "    install.packages(\"corrplot\")  # for correlation plot\n",
    "}\n",
    "if (!require(DAAG)) {\n",
    "    install.packages(\"DAAG\")      # for lm cross valiation\n",
    "}\n",
    "if (!require(glmnet)){\n",
    "    install.packages(\"glmnet\")    # for ridge and lasso model\n",
    "}\n",
    "library(dummies)   # dummy variable\n",
    "library(moments)   # skewness\n",
    "library(corrplot)  # corrplot\n",
    "library(DAAG)      # cross-validation\n",
    "library(glmnet)    # ridge and lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load the data set\n",
    "train = read.csv('./train.csv')\n",
    "test  = read.csv('./test.csv')\n",
    "\n",
    "# combine into one data frame by rows\n",
    "\n",
    "data = rbind(train[, -ncol(train)], test)\n",
    "\n",
    "# compute the number of missing values in each column\n",
    "num.NA = colSums(apply(data[, -1], 2, is.na))\n",
    "# see the class of each variable\n",
    "data.type = sapply(data[, names(which(num.NA != 0))], class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop 6 columns as LotFrontage, Alley, FireplaceQu, PoolQC, Fence, MiscFeature  for more than 200 data are missing\n",
    "drop.names = c(\"LotFrontage\",\"Alley\",\"FireplaceQu\",\"PoolQC\", \"Fence\", \"MiscFeature\")\n",
    "data = data[ , !(names(data) %in% drop.names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find all categorical and numerical variables\n",
    "data.type = sapply(data[ , -1], class)\n",
    "categorical.var = names(data)[which(c(NA, data.type, NA) == 'factor')]\n",
    "numerical.var = names(data)[which(c(NA, data.type, NA) == 'integer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new feature named \"NA\" for categorical variables\n",
    "for (i in categorical.var) {\n",
    "    data[, i] = addNA(data[, i])\n",
    "}\n",
    "\n",
    "# create new features using the median value for all numerical variables with missing values\n",
    "for (i in numerical.var) {\n",
    "    na.id = is.na(data[, i])\n",
    "    tmp.median = median(train[, i], na.rm=TRUE)\n",
    "    data[which(na.id), i] = tmp.median\n",
    "}\n",
    "\n",
    "# transform numerical feature whose skewness is larger than 0.75\n",
    "skewed.features = sapply(data[, numerical.var], skewness)\n",
    "skewed.features = numerical.var[which(skewed.features > 0.75)]\n",
    "for (i in skewed.features) {\n",
    "    data[, i] = log(data[, i] + 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "dummy.var = data.frame(dummy.data.frame(data[, categorical.var], sep='.'))\n",
    "data = cbind(data, dummy.var)\n",
    "\n",
    "# drop original categorical variables\n",
    "data = data[ , !(names(data) %in% categorical.var)]\n",
    "\n",
    "data.train = data[1:nrow(train), ]\n",
    "data.test = data[(nrow(train) + 1):nrow(data), ]\n",
    "\n",
    "data.train['SalePrice'] = log(train$SalePrice+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have (data.train) and (data.test) to continue Ridge and Lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ridge regression\n",
    "pos = ncol(data.train)\n",
    "cv.ridge = cv.glmnet(as.matrix(data.train[,-c(1, pos)]),data.train[,'SalePrice'],nfolds=10 )\n",
    "lambda_ridge = cv.ridge$lambda.min   # this is the optimal lambda with minimal shrinkage\n",
    "#lambda_ridge\n",
    "# use glmnet use alpha = 0 is ridge regression\n",
    "ridge.fit = glmnet(as.matrix(data.train[,-c(1, pos)]),data.train[,'SalePrice'],alpha =0,lambda = lambda_ridge)\n",
    "ridge.pred = exp(predict(ridge.fit, s = lambda_ridge, newx = as.matrix(data.test[,-1])))-1\n",
    "#cv.ridge$cvm\n",
    "submission = read.csv('./sample_submission.csv')\n",
    "submission$SalePrice = ridge.pred\n",
    "write.table(submission, './ridge_Pred_all_k10.csv', row.names = FALSE, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lasso regression\n",
    "cv.lasso = cv.glmnet(as.matrix(data.train[,-c(1, pos)]),data.train[,'SalePrice'],nfolds=10 )\n",
    "lambda_lasso = cv.lasso$lambda.min   # this is the optimal lambda with minimal shrinkage\n",
    "#lambda_lasso\n",
    "# use glmnet use alpha = 1 is lasso regression\n",
    "lasso.fit = glmnet(as.matrix(data.train[,-c(1, pos)]),data.train[,'SalePrice'],alpha = 1,lambda = lambda_lasso)\n",
    "lasso.pred = exp(predict(lasso.fit, s = lambda_lasso, newx = as.matrix(data.test[,-1])))-1\n",
    "#cv.lasso$cvm\n",
    "submission = read.csv('./sample_submission.csv')\n",
    "submission$SalePrice = lasso.pred\n",
    "write.table(submission, './lasso_Pred_all_k10.csv', row.names = FALSE, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
